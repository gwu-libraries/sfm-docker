version: "2"
services:
    db:
        image: gwul/sfm-ui-db:2.3.0
        environment:
            - POSTGRES_PASSWORD
            - TZ
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    mq:
        image: gwul/sfm-rabbitmq:2.3.0
        hostname: mq
        ports:
            # Opens up the ports for RabbitMQ management
            - "${RABBITMQ_MANAGEMENT_PORT}:15672"
        environment:
            - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
            - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
            - TZ
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    # These containers will exit on startup. That's OK.
    data:
        image: gwul/sfm-data:2.3.0
        volumes:
             - ${DATA_VOLUME_MQ}
             - ${DATA_VOLUME_DB}
             - ${DATA_VOLUME_EXPORT}
             - ${DATA_VOLUME_CONTAINERS}
             - ${DATA_VOLUME_COLLECTION_SET}
        environment:
            - TZ
            - SFM_UID
            - SFM_GID
    processingdata:
        image: debian:jessie
        command: /bin/true
        volumes:
             - ${PROCESSING_VOLUME}
        environment:
            - TZ
    ui:
        image: gwul/sfm-ui:2.3.0
        ports:
            - "${SFM_PORT}:8080"
        links:
            - db:db
            - mq:mq
        environment:
            - SFM_DEBUG=False
            - SFM_APSCHEDULER_LOG=INFO
            - SFM_UI_LOG=INFO
            # This adds a 5 minute schedule option to speed testing.
            - SFM_FIVE_MINUTE_SCHEDULE=False
            # This adds a 100 item export segment for testing.
            - SFM_HUNDRED_ITEM_SEGMENT=False
            - TZ
            - SFM_SITE_ADMIN_NAME
            - SFM_SITE_ADMIN_EMAIL
            - SFM_SITE_ADMIN_PASSWORD
            - SFM_EMAIL_USER
            - SFM_EMAIL_PASSWORD
            - SFM_EMAIL_FROM
            - SFM_SMTP_HOST
            - SFM_HOST=${SFM_HOSTNAME}:${SFM_PORT}
            - SFM_HOSTNAME
            - SFM_CONTACT_EMAIL
            - TWITTER_CONSUMER_KEY
            - TWITTER_CONSUMER_SECRET
            - WEIBO_API_KEY
            - WEIBO_API_SECRET
            - TUMBLR_CONSUMER_KEY
            - TUMBLR_CONSUMER_SECRET
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - RABBITMQ_MANAGEMENT_PORT
            - POSTGRES_PASSWORD
            # To have some test accounts created.
            - LOAD_FIXTURES=False
            - SFM_REQS=release
            - DATA_VOLUME_THRESHOLD
            - PROCESSING_VOLUME_THRESHOLD
            - SFM_UID
            - SFM_GID
            - SFM_INSTITUTION_NAME
            - SFM_INSTITUTION_LINK
            - SFM_ENABLE_COOKIE_CONSENT
            - SFM_COOKIE_CONSENT_HTML
            - SFM_COOKIE_CONSENT_BUTTON_TEXT
            - SFM_ENABLE_GW_FOOTER
            - SFM_MONITOR_QUEUE_HOUR_INTERVAL
            - SFM_SCAN_FREE_SPACE_HOUR_INTERVAL
            - SFM_WEIBO_SEARCH_OPTION
            - SFM_USE_HTTPS
            # For ngninx-proxy
            - VIRTUAL_HOST=${SFM_HOSTNAME}
            - VIRTUAL_PORT=${SFM_PORT}
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
            - processingdata
        restart: always
#    # For running SFM with HTTPS
#    # When using this, in .env, SFM_PORT must be 8080 and USE_HTTPS must be True.
#    # For more information on configuration of nginx-proxy, see https://github.com/jwilder/nginx-proxy
#    nginx-proxy:
#        image: jwilder/nginx-proxy
#        ports:
#            - "443:443"
#            - "80:80"
#        environment:
#            - DEFAULT_HOST=${SFM_HOSTNAME}
#        logging:
#            driver: json-file
#            options:
#                max-size: ${DOCKER_LOG_MAX_SIZE}
#                max-file: ${DOCKER_LOG_MAX_FILE}
#        volumes:
#            - /var/run/docker.sock:/tmp/docker.sock:ro
#            # This should point to your local key and certificate
#            # Make sure in the cert that the server cert comes before the intermediate certs.
#            - "./server.crt:/etc/nginx/certs/${SFM_HOSTNAME}.crt"
#            - "./server.key:/etc/nginx/certs/${SFM_HOSTNAME}.key"
#        restart: always
    uiconsumer:
        image: gwul/sfm-ui-consumer:2.3.0
        links:
            - db:db
            - mq:mq
            - ui:ui
        environment:
            - SFM_DEBUG=False
            - SFM_APSCHEDULER_LOG=INFO
            - SFM_UI_LOG=INFO
            - TZ
            - SFM_SITE_ADMIN_NAME
            - SFM_SITE_ADMIN_EMAIL
            - SFM_SITE_ADMIN_PASSWORD
            - SFM_EMAIL_USER
            - SFM_EMAIL_PASSWORD
            - SFM_EMAIL_FROM
            - SFM_SMTP_HOST
            - SFM_HOST=${SFM_HOSTNAME}:${SFM_PORT}
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - POSTGRES_PASSWORD
            - SFM_REQS=release
            - SFM_UID
            - SFM_GID
            - SFM_USE_HTTPS
        volumes_from:
            - data
            - processingdata
        restart: always
# Twitter
    twitterrestharvester:
        image: gwul/sfm-twitter-rest-harvester:2.3.0
        links:
            - mq:mq
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - HARVEST_TRIES=${TWITTER_REST_HARVEST_TRIES}
            - SFM_UID
            - SFM_GID
            - PRIORITY_QUEUES=False
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    twitterpriorityrestharvester:
        image: gwul/sfm-twitter-rest-harvester:2.3.0
        links:
            - mq:mq
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - HARVEST_TRIES=${TWITTER_REST_HARVEST_TRIES}
            - SFM_UID
            - SFM_GID
            - PRIORITY_QUEUES=True
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    twitterstreamharvester:
        image: gwul/sfm-twitter-stream-harvester:2.3.0
        links:
            - mq:mq
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - HARVEST_TRIES=${TWITTER_STREAM_HARVEST_TRIES}
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    twitterrestexporter:
        image: gwul/sfm-twitter-rest-exporter:2.3.0
        links:
            - mq:mq
            - ui:api
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    twitterstreamexporter:
        image: gwul/sfm-twitter-stream-exporter:2.3.0
        links:
            - mq:mq
            - ui:api
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always

# FLICKR
    flickrharvester:
        image: gwul/sfm-flickr-harvester:2.3.0
        links:
            - mq:mq
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - HARVEST_TRIES=${FLICKR_HARVEST_TRIES}
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    flickrexporter:
        image: gwul/sfm-flickr-exporter:2.3.0
        links:
            - mq:mq
            - ui:api
        environment:
            - DEBUG=False
            - TZ
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
# WEIBO
    weiboharvester:
        image: gwul/sfm-weibo-harvester:2.3.0
        links:
            - mq:mq
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - HARVEST_TRIES=${WEIBO_HARVEST_TRIES}
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    weiboexporter:
        image: gwul/sfm-weibo-exporter:2.3.0
        links:
            - mq:mq
            - ui:api
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always

# TUMBLR
    tumblrharvester:
        image: gwul/sfm-tumblr-harvester:2.3.0
        links:
            - mq:mq
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - HARVEST_TRIES=${TUMBLR_HARVEST_TRIES}
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always
    tumblrexporter:
        image: gwul/sfm-tumblr-exporter:2.3.0
        links:
            - mq:mq
            - ui:api
        environment:
            - TZ
            - DEBUG=False
            - RABBITMQ_USER
            - RABBITMQ_PASSWORD
            - SFM_REQS=release
            - SFM_UID
            - SFM_GID
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data
        restart: always

# PROCESSING
    # This container will exit on startup. That's OK.
    processing:
        image: gwul/sfm-processing:2.3.0
        links:
            - ui:api
        environment:
            - TZ
        logging:
            driver: json-file
            options:
                max-size: ${DOCKER_LOG_MAX_SIZE}
                max-file: ${DOCKER_LOG_MAX_FILE}
        volumes_from:
            - data:ro
            - processingdata
